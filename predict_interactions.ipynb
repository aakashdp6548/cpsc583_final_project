{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "import scanpy as sc\n",
    "import anndata\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the embeddings and ground truth data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = \"Lymph Node\"\n",
    "\n",
    "if DATASET == \"Breast Cancer\":\n",
    "    ADATA_PATH = 'data/V1_Breast_Cancer_Block_A_Section_1/breast_cancer.h5ad'\n",
    "    GT_PATH = 'data/V1_Breast_Cancer_Block_A_Section_1/cpdb_scores/thresholded_interaction_matrix.tsv'\n",
    "    dataset_name = \"breast_cancer\"\n",
    "elif DATASET == \"Lymph Node\":\n",
    "    ADATA_PATH = 'data/V1_Human_Lymph_Node/lymph_node.h5ad'\n",
    "    GT_PATH = 'data/V1_Human_Lymph_Node/cpdb_scores/thresholded_interaction_matrix.tsv'\n",
    "    dataset_name = \"lymph_node\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the cell types\n",
    "adata = anndata.read_h5ad(ADATA_PATH)\n",
    "cell_types = adata.obs['leiden'].values.astype(int)\n",
    "\n",
    "# Load the ground truth data\n",
    "ground_truth = pd.read_csv(GT_PATH, sep='\\t', index_col=0).values.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed 42 | Test Accuracy: 0.8560 | Test F1 Score: 0.8583\n",
      "Seed 21 | Test Accuracy: 0.8580 | Test F1 Score: 0.8605\n",
      "Seed 13 | Test Accuracy: 0.8300 | Test F1 Score: 0.8365\n",
      "Average Test Accuracy: 0.8480 ± 0.0128\n",
      "Average Test F1 Score: 0.8518 ± 0.0108\n"
     ]
    }
   ],
   "source": [
    "accuracy_scores = []\n",
    "f1_scores = []\n",
    "\n",
    "for embedding_path in glob.glob(f'training_output/{dataset_name}_seed_*'):\n",
    "    seed = embedding_path.split('_')[-1]\n",
    "    embeddings = torch.load(embedding_path + '/final_embeddings.pt').numpy()\n",
    "    embedding_pairs = []\n",
    "    interaction_labels = []\n",
    "\n",
    "    num_samples = 11000\n",
    "    indices = torch.randint(0, embeddings.shape[0], (num_samples, 2))\n",
    "\n",
    "    embedding_pairs = []\n",
    "    interaction_labels = []\n",
    "\n",
    "    for idx in indices:\n",
    "        i, j = idx\n",
    "        cell_type_i = cell_types[i]\n",
    "        cell_type_j = cell_types[j]\n",
    "        interaction = ground_truth[cell_type_i, cell_type_j]\n",
    "        \n",
    "        concatenated_embedding = np.concatenate((embeddings[i], embeddings[j]))\n",
    "        \n",
    "        embedding_pairs.append(concatenated_embedding)\n",
    "        interaction_labels.append(interaction)\n",
    "\n",
    "    embedding_pairs = np.stack(embedding_pairs)\n",
    "    interaction_labels = np.array(interaction_labels)\n",
    "\n",
    "    # Create train/test split\n",
    "    train_pairs, test_pairs, train_labels, test_labels = train_test_split(\n",
    "        embedding_pairs, interaction_labels, test_size=(1./11), random_state=42\n",
    "    )\n",
    "\n",
    "    # Flatten the embeddings for logistic regression\n",
    "    train_pairs_flat = train_pairs.reshape(train_pairs.shape[0], -1)\n",
    "    test_pairs_flat = test_pairs.reshape(test_pairs.shape[0], -1)\n",
    "\n",
    "    # Initialize the logistic regression model\n",
    "    log_reg = LogisticRegression(max_iter=1000)\n",
    "\n",
    "    # Train the model\n",
    "    log_reg.fit(train_pairs_flat, train_labels)\n",
    "\n",
    "    # Predict on the test set\n",
    "    test_predictions = log_reg.predict(test_pairs_flat)\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(test_labels, test_predictions)\n",
    "    f1 = f1_score(test_labels, test_predictions)\n",
    "\n",
    "    print(f\"Seed {seed} | Test Accuracy: {accuracy:.4f} | Test F1 Score: {f1:.4f}\")\n",
    "\n",
    "    accuracy_scores.append(accuracy)\n",
    "    f1_scores.append(f1)\n",
    "\n",
    "print(f\"Average Test Accuracy: {np.mean(accuracy_scores):.4f} ± {np.std(accuracy_scores):.4f}\")\n",
    "print(f\"Average Test F1 Score: {np.mean(f1_scores):.4f} ± {np.std(f1_scores):.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare against logistic regression model on expression data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs × n_vars = 4022 × 2000\n",
       "    obs: 'in_tissue', 'array_row', 'array_col', 'n_genes', 'n_genes_by_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt', 'leiden'\n",
       "    var: 'gene_ids', 'feature_types', 'genome', 'n_cells', 'mt', 'n_cells_by_counts', 'mean_counts', 'pct_dropout_by_counts', 'total_counts', 'highly_variable', 'means', 'dispersions', 'dispersions_norm', 'mean', 'std'\n",
       "    uns: 'hvg', 'leiden', 'leiden_colors', 'log1p', 'neighbors', 'pca', 'spatial', 'umap'\n",
       "    obsm: 'X_pca', 'X_umap', 'spatial'\n",
       "    varm: 'PCs'\n",
       "    layers: 'log_norm'\n",
       "    obsp: 'connectivities', 'distances'"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.pp.highly_variable_genes(adata, flavor='cell_ranger', n_top_genes=2000, subset=True)\n",
    "adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 46 | Test Accuracy: 0.8220 | Test F1 Score: 0.8282\n",
      "Run 3145 | Test Accuracy: 0.8260 | Test F1 Score: 0.8214\n",
      "Run 3540 | Test Accuracy: 0.8240 | Test F1 Score: 0.8163\n",
      "Average Test Accuracy: 0.8240 ± 0.0016\n",
      "Average Test F1 Score: 0.8219 ± 0.0049\n"
     ]
    }
   ],
   "source": [
    "accuracy_scores = []\n",
    "f1_scores = []\n",
    "\n",
    "for i in range(3):\n",
    "    embeddings = adata.X.toarray()\n",
    "    embedding_pairs = []\n",
    "    interaction_labels = []\n",
    "\n",
    "    num_samples = 11000\n",
    "    indices = torch.randint(0, embeddings.shape[0], (num_samples, 2))\n",
    "\n",
    "    embedding_pairs = []\n",
    "    interaction_labels = []\n",
    "\n",
    "    for idx in indices:\n",
    "        i, j = idx\n",
    "        cell_type_i = cell_types[i]\n",
    "        cell_type_j = cell_types[j]\n",
    "        interaction = ground_truth[cell_type_i, cell_type_j]\n",
    "        \n",
    "        concatenated_embedding = np.concatenate((embeddings[i], embeddings[j]))\n",
    "        \n",
    "        embedding_pairs.append(concatenated_embedding)\n",
    "        interaction_labels.append(interaction)\n",
    "\n",
    "    embedding_pairs = np.stack(embedding_pairs)\n",
    "    interaction_labels = np.array(interaction_labels)\n",
    "\n",
    "    # Create train/test split\n",
    "    train_pairs, test_pairs, train_labels, test_labels = train_test_split(\n",
    "        embedding_pairs, interaction_labels, test_size=(1./11), random_state=42\n",
    "    )\n",
    "\n",
    "    # Flatten the embeddings for logistic regression\n",
    "    train_pairs_flat = train_pairs.reshape(train_pairs.shape[0], -1)\n",
    "    test_pairs_flat = test_pairs.reshape(test_pairs.shape[0], -1)\n",
    "\n",
    "    # Initialize the logistic regression model\n",
    "    log_reg = LogisticRegression(max_iter=1000)\n",
    "\n",
    "    # Train the model\n",
    "    log_reg.fit(train_pairs_flat, train_labels)\n",
    "\n",
    "    # Predict on the test set\n",
    "    test_predictions = log_reg.predict(test_pairs_flat)\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(test_labels, test_predictions)\n",
    "    f1 = f1_score(test_labels, test_predictions)\n",
    "\n",
    "    print(f\"Run {i} | Test Accuracy: {accuracy:.4f} | Test F1 Score: {f1:.4f}\")\n",
    "\n",
    "    accuracy_scores.append(accuracy)\n",
    "    f1_scores.append(f1)\n",
    "\n",
    "print(f\"Average Test Accuracy: {np.mean(accuracy_scores):.4f} ± {np.std(accuracy_scores):.4f}\")\n",
    "print(f\"Average Test F1 Score: {np.mean(f1_scores):.4f} ± {np.std(f1_scores):.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
